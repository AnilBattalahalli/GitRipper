{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import sys\n",
    "import time\n",
    "sys.path.append('/home/sreenath_a/Projects/OSS/Production/GitRipper')\n",
    "\n",
    "import pandas as pd\n",
    "from GitRipper.Ripper import collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_count = os.cpu_count()\n",
    "print(cpu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['owner', 'repo', 'name', 'description', 'licenseName', 'licenseSpdxId', 'licenseUrl',\n",
    "           'shortDescriptionHTML', 'repourl', 'createdAt', 'updatedAt', 'pushedAt',\n",
    "           'forkCount', 'stargazerCount', 'issuesCount', 'pullRequestsCount', 'readme']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelcount = cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the json file\n",
    "with open('/home/sreenath_a/Projects/OSS/API_keys.json') as f:\n",
    "    keys = json.load(f)['keys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty dataframe and save as csv\n",
    "if not os.path.exists('/home/sreenath_a/Projects/OSS/Production/Julia_GH_Data_Repos.csv'):\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    df.to_csv('/home/sreenath_a/Projects/OSS/Production/Julia_GH_Data_Repos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the packages alrady collected\n",
    "slugs_collected = []\n",
    "for df in pd.read_csv('/home/sreenath_a/Projects/OSS/Production/Julia_GH_Data_Repos.csv', chunksize=1000):\n",
    "    repo_names = df['repo'].tolist()\n",
    "    repo_owners = df['owner'].tolist()\n",
    "    for i in range(len(repo_names)):\n",
    "        slugs_collected.append(repo_owners[i] + '/' + repo_names[i])\n",
    "    slugs_collected = [i.strip() for i in list(set(slugs_collected))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_owner_and_repo(url):\n",
    "    ### if it has .git, remove it\n",
    "    if url.endswith(\".git\"):\n",
    "        url = url[:-4]\n",
    "    ### get owner and repo\n",
    "    owner = url.split(\"/\")[-2]\n",
    "    repo = url.split(\"/\")[-1]\n",
    "    return owner, repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list = [(i.split(\":\")[0], i.split(\":\")[1]) for i in keys]\n",
    "collector = collect(keys_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?collector.getRepoInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_info(owner, repo, key=None):\n",
    "    try:\n",
    "        if owner + '/' + repo in slugs_collected:\n",
    "            return None\n",
    "        repo_info = collector.getRepoInfo(owner, repo, key)\n",
    "        return repo_info\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_owner_and_repo(url):\n",
    "    ### if it has .git, remove it\n",
    "    if url.endswith(\".git\"):\n",
    "        url = url[:-4]\n",
    "    ### get owner and repo\n",
    "    owner = url.split(\"/\")[-2]\n",
    "    repo = url.split(\"/\")[-1]\n",
    "    return owner, repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pacakges = pd.read_csv(\"/home/sreenath_a/Projects/OSS/nsf-oss/Data_Collection/Julia_data_collection/Julia_Packages_all.csv\").shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in tqdm(pd.read_csv(\"/home/sreenath_a/Projects/OSS/nsf-oss/Data_Collection/Julia_data_collection/Julia_Packages_all.csv\", chunksize=parallelcount), total=total_pacakges//parallelcount):\n",
    "    try:\n",
    "        slugs = [get_owner_and_repo(i) for i in df.RepoURL]\n",
    "        owners = [i[0] for i in slugs]\n",
    "        repos = [i[1] for i in slugs]\n",
    "        owners = [i[0] for i in slugs]\n",
    "        repos = [i[1] for i in slugs]\n",
    "        best_keys = collector.getBestKeys(n=parallelcount)\n",
    "        args = list(zip(owners, repos, best_keys))\n",
    "    except:\n",
    "        continue\n",
    "    with Pool(parallelcount) as p:\n",
    "        result = p.starmap(get_repo_info, args)\n",
    "    result = [i for i in result if i is not None]\n",
    "    if len(result) == 0:\n",
    "        continue\n",
    "    result_df = pd.DataFrame.from_dict(result, orient='columns')\n",
    "    result_df.to_csv('/home/sreenath_a/Projects/OSS/Production/Julia_GH_Data_Repos.csv', mode='a', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OSS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
