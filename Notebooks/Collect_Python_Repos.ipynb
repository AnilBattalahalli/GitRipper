{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import sys\n",
    "from random import choice, randint\n",
    "import time\n",
    "sys.path.append('/home/sreenath_a/Projects/OSS/Production/GitRipper')\n",
    "\n",
    "import pandas as pd\n",
    "from GitRipper.Ripper import collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_data_path = '/home/sreenath_a/Projects/OSS/nsf-oss/Data_Collection/Python_data_collection/PyPi_metadata_flattened_wh.csv'\n",
    "repo_owner_path = '/home/sreenath_a/Projects/OSS/Production/PyPi_Repo_Owner.csv'\n",
    "repos_info_path = '/home/sreenath_a/Projects/OSS/Production/PyPi_GH_Data_Repos.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_owner_and_repo(url):\n",
    "#     if type(url) != str:\n",
    "#         return None, None\n",
    "#     if \"/\" not in url:\n",
    "#         return None, None\n",
    "#     url = str(url).strip()\n",
    "#     if url.endswith(\".git\"):\n",
    "#         url = url[:-4]\n",
    "#     owner = url.split(\"/\")[-2]\n",
    "#     repo = url.split(\"/\")[-1]\n",
    "#     return owner, repo\n",
    "\n",
    "# def get_url(url_dict):\n",
    "#     if url_dict is None:\n",
    "#         return None\n",
    "#     url_list = list(url_dict.values())\n",
    "#     url_list = [i for i in url_list if \"github.com\" in i]\n",
    "#     if len(url_list) == 0:\n",
    "#         return None\n",
    "#     u = [i for i in url_list if \"github.com\" in i.split(\"/\")[-3]]\n",
    "#     if len(u) == 0:\n",
    "#         url = url_list[0]\n",
    "#         url = \"/\".join(url.split(\"/\")[:5])\n",
    "#         if \"github.com\" in url.split(\"/\")[2]:\n",
    "#             return url\n",
    "#         else:\n",
    "#             return None\n",
    "#     else:\n",
    "#         url =  u[0]\n",
    "#         return url\n",
    "\n",
    "# # Create a blank csv file with the required columns: package_name, project_urls, owner, repo\n",
    "# df = pd.DataFrame(columns=['package_name', 'project_urls', 'owner', 'repo'])\n",
    "# df.to_csv(repo_owner_path, index=False)\n",
    "# for df in tqdm(pd.read_csv(repos_data_path, chunksize=8000), total=450000/8000):\n",
    "#     for row in df.iterrows():\n",
    "#         try:\n",
    "#             package_name = row[1]['PackageName']\n",
    "#             project_urls = row[1]['project_urls']\n",
    "#             if type(project_urls) != str:\n",
    "#                 continue\n",
    "#             owner, repo = get_owner_and_repo(get_url(ast.literal_eval(project_urls)))\n",
    "#             if owner is None or repo is None:\n",
    "#                 continue\n",
    "#             df = pd.DataFrame([[package_name, project_urls, owner, repo]], columns=['package_name', 'project_urls', 'owner', 'repo'])\n",
    "#             df.to_csv(repo_owner_path, mode='a', header=False, index=False)\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "#             continue\n",
    "# urls_json = choice(df.project_urls)\n",
    "# if pd.isna(urls_json):\n",
    "#     print(\"The url_dict is: None\")\n",
    "#     print(\"The url is: None\")\n",
    "# else:\n",
    "#     urls_dict = ast.literal_eval(urls_json)\n",
    "#     url = get_url(urls_dict)\n",
    "#     print(\"The url_dict is: \", urls_dict)\n",
    "#     print(\"The url is: \", url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "cpu_count = os.cpu_count()\n",
    "print(cpu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['owner', 'repo', 'name', 'description', 'licenseName', 'licenseSpdxId', 'licenseUrl',\n",
    "           'shortDescriptionHTML', 'repourl', 'createdAt', 'updatedAt', 'pushedAt',\n",
    "           'forkCount', 'stargazerCount', 'issuesCount', 'pullRequestsCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelcount = cpu_count\n",
    "#parallelcount = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the json file\n",
    "with open('/home/sreenath_a/Projects/OSS/API_keys.json') as f:\n",
    "    keys = json.load(f)['keys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty dataframe and save as csv\n",
    "if not os.path.exists(repos_info_path):\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    df.to_csv(repos_info_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the packages alrady collected\n",
    "slugs_collected = []\n",
    "for df in pd.read_csv(repos_info_path, chunksize=1000):\n",
    "    repo_names = df['repo'].tolist()\n",
    "    repo_owners = df['owner'].tolist()\n",
    "    for i in range(len(repo_names)):\n",
    "        slugs_collected.append(str(repo_owners[i]).strip() + '/' + str(repo_names[i]).strip())\n",
    "    slugs_collected = [i.strip() for i in list(set(slugs_collected))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed with status code: 401\n",
      "Key gkorkmaz failed\n",
      "Query failed with status code: 401\n",
      "Key Naskew failed\n",
      "Query failed with status code: 401\n",
      "Key rahuloms failed\n"
     ]
    }
   ],
   "source": [
    "keys_list = [(i.split(\":\")[0], i.split(\":\")[1]) for i in keys]\n",
    "collector = collect(keys_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_info(owner, repo, key=None):\n",
    "    time_to_sleep = randint(5, 10)\n",
    "    try:\n",
    "        owner = str(owner).strip()\n",
    "        repo = str(repo).strip()\n",
    "        if owner + '/' + repo in slugs_collected:\n",
    "            return None\n",
    "        time.sleep(time_to_sleep/10)\n",
    "        repo_info = collector.getRepoInfo(owner, repo, key)\n",
    "        del repo_info['readme']\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    return repo_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_owner_and_repo(url):\n",
    "    if type(url) != str:\n",
    "        return None, None\n",
    "    if \"/\" not in url:\n",
    "        return None, None\n",
    "    url = str(url).strip()\n",
    "    if url.endswith(\".git\"):\n",
    "        url = url[:-4]\n",
    "    owner = url.split(\"/\")[-2]\n",
    "    repo = url.split(\"/\")[-1]\n",
    "    return owner, repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258573\n"
     ]
    }
   ],
   "source": [
    "total_pacakges = pd.read_csv(repo_owner_path).shape[0]\n",
    "print(total_pacakges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slugs collected:  54539\n",
      "Packages to collect:  204034\n"
     ]
    }
   ],
   "source": [
    "print(\"Slugs collected: \", len(slugs_collected))\n",
    "print(\"Packages to collect: \", total_pacakges - len(slugs_collected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 32/12928 [00:33<4:01:36,  1.12s/it]"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "best_keys = collector.getBestKeys(n=parallelcount)\n",
    "for df in tqdm(pd.read_csv(repo_owner_path, chunksize=parallelcount), total=total_pacakges//parallelcount):\n",
    "    df['slugs'] = df['owner'] + '/' + df['repo']\n",
    "    df = df[~df['slugs'].isin(slugs_collected)]\n",
    "    if df.shape[0] == 0:\n",
    "        continue\n",
    "    owners = df['owner'].tolist()\n",
    "    repos = df['repo'].tolist()\n",
    "    args = list(zip(owners, repos, best_keys))\n",
    "    with Pool(parallelcount) as p:\n",
    "        result = p.starmap(get_repo_info, args)\n",
    "    result = [i for i in result if i is not None]\n",
    "    if len(result) == 0:\n",
    "        continue\n",
    "    result_df = pd.DataFrame.from_dict(result, orient='columns')\n",
    "    result_df = result_df[result_df.owner.notna()].reset_index(drop=True)\n",
    "    if result_df.shape[0] == 0:\n",
    "        continue\n",
    "    result_df.to_csv(repos_info_path, mode='a', header=False, index=False)\n",
    "    i = i+1\n",
    "    if i%200 == 0:\n",
    "        best_keys = collector.getBestKeys(n=parallelcount)\n",
    "        waittime = randint(10, 60)\n",
    "        time.sleep(waittime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repos = pd.read_csv(repos_info_path)\n",
    "df_repos = df_repos[df_repos.owner.notna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repos.to_csv(repos_info_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OSS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
